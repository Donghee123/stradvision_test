{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongheehan/anaconda3/envs/objectdetection/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.ops \n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as func\n",
    "import cv2\n",
    "import numpy as np\n",
    "from detectron2.evaluation.coco_evaluation import instances_to_coco_json\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.data import MetadataCatalog\n",
    "import pickle\n",
    "from fiftyone import ViewField as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config /home/dongheehan/anaconda3/envs/objectdetection/lib/python3.7/site-packages/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n",
      "[Checkpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_1x/190397773/model_final_bfca0b.pkl ...\n",
      "URL https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_1x/190397773/model_final_bfca0b.pkl cached in /home/dongheehan/.torch/iopath_cache/detectron2/COCO-Detection/retinanet_R_50_FPN_1x/190397773/model_final_bfca0b.pkl\n",
      "Reading a file from 'Detectron2 Model Zoo'\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n",
      "Model ready\n"
     ]
    }
   ],
   "source": [
    "# select device (whether GPU or CPU)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "inferencemode = 'COCO-Detection'\n",
    "expendName = '.yaml'\n",
    "load_model_name1 = 'retinanet_R_50_FPN_1x'\n",
    "load_model_name = 'ensemble_union'\n",
    "\n",
    "# load model\n",
    "cfg = get_cfg()\n",
    "\n",
    "cfg.merge_from_file(model_zoo.get_config_file(os.path.join(inferencemode, load_model_name1 + expendName)))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "#Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(os.path.join(inferencemode, load_model_name1 + expendName))\n",
    "predictor1 = DefaultPredictor(cfg)\n",
    "predictor1.model.eval()\n",
    "\n",
    "PREDICTION_PATH = './predictions'\n",
    "\n",
    "# load\n",
    "with open(os.path.join(PREDICTION_PATH, f'{load_model_name}_predictions.pickle'), 'rb') as f:\n",
    "    model1_predictions = pickle.load(f)\n",
    "\n",
    "print(\"Model ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'validation' to '/home/dongheehan/fiftyone/coco-2017/validation' if necessary\n",
      "Found annotations at '/home/dongheehan/fiftyone/coco-2017/raw/instances_val2017.json'\n",
      "Images already downloaded\n",
      "Existing download of split 'validation' is sufficient\n",
      "Loading existing dataset 'evaluate-ensenble-detections'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      "Name:        evaluate-ensenble-detections\n",
      "Media type:  image\n",
      "Num samples: 5000\n",
      "Persistent:  True\n",
      "Tags:        ['validation']\n",
      "Sample fields:\n",
      "    id:                            fiftyone.core.fields.ObjectIdField\n",
      "    filepath:                      fiftyone.core.fields.StringField\n",
      "    tags:                          fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:                      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    ground_truth:                  fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    ensemble:                      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    eval4_tp:                      fiftyone.core.fields.IntField\n",
      "    eval4_fp:                      fiftyone.core.fields.IntField\n",
      "    eval4_fn:                      fiftyone.core.fields.IntField\n",
      "    eval_union_tp:                 fiftyone.core.fields.IntField\n",
      "    eval_union_fp:                 fiftyone.core.fields.IntField\n",
      "    eval_union_fn:                 fiftyone.core.fields.IntField\n",
      "    eval_f1ranking_tp:             fiftyone.core.fields.IntField\n",
      "    eval_f1ranking_fp:             fiftyone.core.fields.IntField\n",
      "    eval_f1ranking_fn:             fiftyone.core.fields.IntField\n",
      "    eval_retinanet_r_50_fpn_1x_tp: fiftyone.core.fields.IntField\n",
      "    eval_retinanet_r_50_fpn_1x_fp: fiftyone.core.fields.IntField\n",
      "    eval_retinanet_r_50_fpn_1x_fn: fiftyone.core.fields.IntField\n",
      "<Detection: {\n",
      "    'id': '62a3fd06fdfbb6089ce458c6',\n",
      "    'attributes': BaseDict({}),\n",
      "    'tags': BaseList([]),\n",
      "    'label': 'potted plant',\n",
      "    'bounding_box': BaseList([\n",
      "        0.37028125,\n",
      "        0.3345305164319249,\n",
      "        0.038593749999999996,\n",
      "        0.16314553990610328,\n",
      "    ]),\n",
      "    'mask': None,\n",
      "    'confidence': None,\n",
      "    'index': None,\n",
      "    'supercategory': 'furniture',\n",
      "    'iscrowd': 0,\n",
      "    'eval4': 'tp',\n",
      "    'eval4_id': '62a4d61f140b464e4fa7fe6a',\n",
      "    'eval4_iou': 0.5737284663218926,\n",
      "    'eval_union': 'fn',\n",
      "    'eval_union_id': '',\n",
      "    'eval_f1ranking': 'fn',\n",
      "    'eval_f1ranking_id': '',\n",
      "    'eval_retinanet_r_50_fpn_1x': 'fn',\n",
      "    'eval_retinanet_r_50_fpn_1x_id': '',\n",
      "}>\n"
     ]
    }
   ],
   "source": [
    "dataset = foz.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    split=\"validation\",\n",
    "    dataset_name=\"evaluate-ensenble-detections\",\n",
    ")\n",
    "\n",
    "dataset.persistent = True\n",
    "\n",
    "# Print some information about the dataset\n",
    "print(dataset)\n",
    "\n",
    "# Print a ground truth detection\n",
    "sample = dataset.first()\n",
    "print(sample.ground_truth.detections[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions_view = dataset.take(5000,seed=51) # limit size\n",
    "\n",
    "# Add predictions to samples\n",
    "predictions= []\n",
    "with fo.ProgressBar() as pb:\n",
    "    for sample in pb(predictions_view):\n",
    "\n",
    "        # Load image\n",
    "        image = cv2.imread(sample.filepath)\n",
    "        h, w, c = image.shape\n",
    "\n",
    "        filename = os.path.basename(sample.filepath)\n",
    "\n",
    "        detections = model1_predictions[filename]\n",
    "\n",
    "        sample[load_model_name] = fo.Detections(detections=detections)\n",
    "        sample.save()\n",
    "\n",
    "print(\"Finished adding predictions\")\n",
    "session.view = None\n",
    "session.view = predictions_view\n",
    "session.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only contains detections with confidence >= 0.75\n",
    "high_conf_view = dataset.filter_labels(load_model_name, F(\"confidence\") > 0.15)\n",
    "\n",
    "print(high_conf_view)\n",
    "\n",
    "sample = high_conf_view.first()\n",
    "print(sample.ensemble.detections[0])\n",
    "\n",
    "session.view = high_conf_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections...\n",
      " 100% |███████████████| 4995/4995 [18.7m elapsed, 0s remaining, 4.1 samples/s]      \n",
      "Performing IoU sweep...\n",
      " 100% |███████████████| 4995/4995 [7.6m elapsed, 0s remaining, 11.2 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "eval_key = load_model_name\n",
    "\n",
    "results = high_conf_view.evaluate_detections(\n",
    "    load_model_name,\n",
    "    gt_field=\"ground_truth\",\n",
    "    eval_key=eval_key,\n",
    "    compute_mAP=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"key\": \"ensemble_union\",\n",
      "    \"version\": \"0.16.2\",\n",
      "    \"timestamp\": \"2022-06-11T21:39:20.836000\",\n",
      "    \"config\": {\n",
      "        \"method\": \"coco\",\n",
      "        \"cls\": \"fiftyone.utils.eval.coco.COCOEvaluationConfig\",\n",
      "        \"pred_field\": \"ensemble_union\",\n",
      "        \"gt_field\": \"ground_truth\",\n",
      "        \"iou\": 0.5,\n",
      "        \"classwise\": true,\n",
      "        \"iscrowd\": \"iscrowd\",\n",
      "        \"use_masks\": false,\n",
      "        \"use_boxes\": false,\n",
      "        \"tolerance\": null,\n",
      "        \"compute_mAP\": true,\n",
      "        \"iou_threshs\": [\n",
      "            0.5,\n",
      "            0.55,\n",
      "            0.6,\n",
      "            0.65,\n",
      "            0.7,\n",
      "            0.75,\n",
      "            0.8,\n",
      "            0.85,\n",
      "            0.9,\n",
      "            0.95\n",
      "        ],\n",
      "        \"max_preds\": 100,\n",
      "        \"error_level\": 1\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(dataset.get_evaluation_info(eval_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "        person       0.34      0.97      0.51     34218\n",
      "           car       0.14      0.93      0.25      3500\n",
      "         chair       0.11      0.85      0.19      2831\n",
      "          book       0.33      0.96      0.49      6657\n",
      "        bottle       0.17      0.92      0.29      2312\n",
      "           cup       0.10      0.87      0.18      1121\n",
      "  dining table       0.05      0.73      0.09       748\n",
      " traffic light       0.07      0.79      0.13       712\n",
      "          bowl       0.08      0.86      0.15       748\n",
      "       handbag       0.04      0.70      0.08       540\n",
      "          bird       0.32      0.94      0.48      1887\n",
      "          boat       0.15      0.92      0.26      1014\n",
      "         truck       0.06      0.88      0.11       427\n",
      "      umbrella       0.18      0.90      0.29       757\n",
      "         bench       0.06      0.77      0.12       610\n",
      "           cow       0.29      0.96      0.44      1042\n",
      "        banana       0.27      0.94      0.42      1504\n",
      "    motorcycle       0.17      0.93      0.28       676\n",
      "        carrot       0.17      0.93      0.29      1215\n",
      "      backpack       0.04      0.70      0.08       371\n",
      "         sheep       0.23      0.97      0.37       921\n",
      "    wine glass       0.12      0.87      0.21       462\n",
      "  potted plant       0.06      0.82      0.11       355\n",
      "         donut       0.35      0.95      0.51      1242\n",
      "          kite       0.32      0.95      0.48      1117\n",
      "         knife       0.05      0.70      0.09       336\n",
      "       bicycle       0.08      0.82      0.14       351\n",
      "      broccoli       0.11      0.93      0.20       677\n",
      "          cake       0.19      0.94      0.31       777\n",
      "      suitcase       0.17      0.93      0.29       652\n",
      "            tv       0.10      0.86      0.18       288\n",
      "        orange       0.10      0.82      0.18       427\n",
      "           bus       0.14      0.89      0.24       309\n",
      "         pizza       0.10      0.85      0.17       289\n",
      "        remote       0.07      0.80      0.13       283\n",
      "          vase       0.06      0.85      0.12       292\n",
      "         horse       0.09      0.90      0.16       273\n",
      "     surfboard       0.07      0.75      0.13       269\n",
      "         zebra       0.23      0.96      0.37       366\n",
      "         clock       0.10      0.87      0.18       267\n",
      "   sports ball       0.25      0.92      0.40       724\n",
      "    cell phone       0.06      0.78      0.11       262\n",
      "         couch       0.07      0.82      0.12       261\n",
      "      elephant       0.30      0.98      0.45       551\n",
      "           tie       0.10      0.83      0.18       357\n",
      "         spoon       0.04      0.69      0.08       253\n",
      "          skis       0.05      0.75      0.09       241\n",
      "         apple       0.15      0.87      0.26       627\n",
      "       giraffe       0.18      0.93      0.29       232\n",
      "        laptop       0.09      0.84      0.16       231\n",
      "          sink       0.06      0.85      0.11       225\n",
      " tennis racket       0.11      0.88      0.20       225\n",
      "           dog       0.10      0.87      0.18       218\n",
      "          fork       0.05      0.77      0.10       215\n",
      "           cat       0.15      0.93      0.26       202\n",
      "    teddy bear       0.09      0.79      0.16       195\n",
      "         train       0.13      0.91      0.23       190\n",
      "        toilet       0.12      0.89      0.22       179\n",
      "    skateboard       0.08      0.86      0.15       179\n",
      "      sandwich       0.06      0.72      0.10       177\n",
      "           bed       0.06      0.74      0.12       163\n",
      "      keyboard       0.08      0.88      0.14       153\n",
      "baseball glove       0.08      0.74      0.14       148\n",
      "  baseball bat       0.06      0.66      0.12       147\n",
      "      airplane       0.12      0.92      0.21       143\n",
      "          oven       0.06      0.80      0.11       143\n",
      "       hot dog       0.16      0.84      0.27       269\n",
      "  refrigerator       0.07      0.83      0.13       126\n",
      "       frisbee       0.13      0.92      0.22       115\n",
      "         mouse       0.09      0.88      0.17       106\n",
      "  fire hydrant       0.14      0.87      0.24       101\n",
      "     stop sign       0.11      0.87      0.19        75\n",
      "          bear       0.22      0.94      0.36        71\n",
      "     snowboard       0.04      0.74      0.08        69\n",
      " parking meter       0.10      0.82      0.18        60\n",
      "    toothbrush       0.03      0.61      0.05        57\n",
      "     microwave       0.08      0.91      0.14        55\n",
      "      scissors       0.03      0.50      0.05        36\n",
      "    hair drier       0.02      0.36      0.04        11\n",
      "       toaster       0.03      0.67      0.05         9\n",
      "\n",
      "     micro avg       0.18      0.93      0.30     80644\n",
      "     macro avg       0.12      0.84      0.21     80644\n",
      "  weighted avg       0.25      0.93      0.38     80644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the 10 most common classes in the dataset\n",
    "counts = dataset.count_values(\"ground_truth.detections.label\")\n",
    "classes_top = sorted(counts, key=counts.get, reverse=True)\n",
    "\n",
    "# Print a classification report for the top-10 classes\n",
    "results.print_report(classes=classes_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2728808887914399\n"
     ]
    }
   ],
   "source": [
    "print(results.mAP())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59b3c8b4d184c9fa97cb69be64af4ac62d59b4aa4e9f32c8b33c27b6076bd8d0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('objectdetection')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
