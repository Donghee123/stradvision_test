{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.ops \n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as func\n",
    "import cv2\n",
    "import numpy as np\n",
    "from detectron2.evaluation.coco_evaluation import instances_to_coco_json\n",
    "from detectron2.structures import BoxMode\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select device (whether GPU or CPU)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "inferencemode = 'COCO-Detection'\n",
    "expendName = '.yaml'\n",
    "load_model_name = 'retinanet_R_50_FPN_3x'\n",
    "\n",
    "# load model\n",
    "cfg = get_cfg()\n",
    "\n",
    "cfg.merge_from_file(model_zoo.get_config_file(os.path.join(inferencemode, load_model_name + expendName)))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "#Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(os.path.join(inferencemode, load_model_name + expendName))\n",
    "\n",
    "PREDICTION_PATH = './predictions'\n",
    "# load\n",
    "with open(os.path.join(PREDICTION_PATH, f'{load_model_name}_predictions.pickle'), 'rb') as f:\n",
    "    model_predictions = pickle.load(f)\n",
    "    \n",
    "print(\"Model ready\")\n",
    "\n",
    "dataset = foz.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    split=\"validation\",\n",
    "    dataset_name=\"evaluate-detections-tutorial\",\n",
    ")\n",
    "dataset.persistent = True\n",
    "\n",
    "# Print some information about the dataset\n",
    "print(dataset)\n",
    "\n",
    "# Print a ground truth detection\n",
    "sample = dataset.first()\n",
    "print(sample.ground_truth.detections[0])\n",
    "\n",
    "session = fo.launch_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import MetadataCatalog\n",
    "import pickle\n",
    "\n",
    "# Choose a random subset of 100 samples to add predictions to\n",
    "predictions_view = dataset.take(5000,seed=51) # limit size\n",
    "\n",
    "## Get class list\n",
    "#classes = dataset.default_classes\n",
    "\n",
    "#Get class list\n",
    "metadata = MetadataCatalog.get(cfg.DATASETS.TRAIN[0])\n",
    "classes = metadata.get(\"thing_classes\", None)\n",
    "\n",
    "overlabthreshold = 0.15\n",
    "\n",
    "# Add predictions to samples\n",
    "with fo.ProgressBar() as pb:\n",
    "    for sample in pb(predictions_view):\n",
    "\n",
    "        # Load image\n",
    "        image = cv2.imread(sample.filepath)\n",
    "        h, w, c = image.shape\n",
    "\n",
    "                # Perform inference\n",
    "        filename = os.path.basename(sample.filepath)\n",
    "        prediction = model_predictions[filename]\n",
    "\n",
    "        boxes =  prediction[0]\n",
    "        labels = prediction[1]\n",
    "        scores = prediction[2]\n",
    "        \n",
    "        tensor_boxes =  torch.tensor(boxes)\n",
    "        tensor_scores = torch.tensor(scores)\n",
    "        results = torchvision.ops.nms(tensor_boxes, tensor_scores, overlabthreshold)\n",
    "        \n",
    "        # Convert detections to FiftyOne format\n",
    "        detections = []\n",
    "\n",
    "        for nIndex, (label, score, box) in enumerate(zip(labels, scores, boxes)):\n",
    "\n",
    "            if (nIndex in results) is False:\n",
    "                continue\n",
    "\n",
    "            x, y, width, height = box\n",
    "\n",
    "            x1 = x\n",
    "            y1 = y\n",
    "            x2 = x + width\n",
    "            y2 = y + height\n",
    "            \n",
    "            rel_box = [x1 / w, y1 / h, (x2 - x1) / w, (y2 - y1) / h]\n",
    "\n",
    "            detections.append(\n",
    "                fo.Detection(\n",
    "                    label=classes[label],\n",
    "                    bounding_box=rel_box,\n",
    "                    confidence=score\n",
    "                )\n",
    "            )\n",
    "        sample[load_model_name] = fo.Detections(detections=detections)\n",
    "        sample.save()\n",
    "\n",
    "\n",
    "print(\"Finished adding predictions\")\n",
    "session.view = None\n",
    "session.view = predictions_view\n",
    "session.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiftyone_classes = dataset.default_classes\n",
    "\n",
    "#Get class list\n",
    "metadata = MetadataCatalog.get(cfg.DATASETS.TRAIN[0])\n",
    "COCO_classes = metadata.get(\"thing_classes\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', '12', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', '26', 'backpack', 'umbrella', '29', '30', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', '45', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', '66', 'dining table', '68', '69', 'toilet', '71', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', '83', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "print(fiftyone_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "print(COCO_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone import ViewField as F\n",
    "\n",
    "# Only contains detections with confidence >= 0.75\n",
    "high_conf_view = dataset.filter_labels(load_model_name, F(\"confidence\") > 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:     evaluate-detections-tutorial\n",
      "Media type:  image\n",
      "Num samples: 4990\n",
      "Tags:        ['validation']\n",
      "Sample fields:\n",
      "    id:                        fiftyone.core.fields.ObjectIdField\n",
      "    filepath:                  fiftyone.core.fields.StringField\n",
      "    tags:                      fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:                  fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    ground_truth:              fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    retinanet_R_50_FPN_1x:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    retinanet_R_50_FPN_3x:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    retinanet_R_101_FPN_3x:    fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    eval2_tp:                  fiftyone.core.fields.IntField\n",
      "    eval2_fp:                  fiftyone.core.fields.IntField\n",
      "    eval2_fn:                  fiftyone.core.fields.IntField\n",
      "    eval3_tp:                  fiftyone.core.fields.IntField\n",
      "    eval3_fp:                  fiftyone.core.fields.IntField\n",
      "    eval3_fn:                  fiftyone.core.fields.IntField\n",
      "    eval_tp:                   fiftyone.core.fields.IntField\n",
      "    eval_fp:                   fiftyone.core.fields.IntField\n",
      "    eval_fn:                   fiftyone.core.fields.IntField\n",
      "    retinenet_R_101_fpn_3x_tp: fiftyone.core.fields.IntField\n",
      "    retinenet_R_101_fpn_3x_fp: fiftyone.core.fields.IntField\n",
      "    retinenet_R_101_fpn_3x_fn: fiftyone.core.fields.IntField\n",
      "    retinenet_R_50_fpn_1x_tp:  fiftyone.core.fields.IntField\n",
      "    retinenet_R_50_fpn_1x_fp:  fiftyone.core.fields.IntField\n",
      "    retinenet_R_50_fpn_1x_fn:  fiftyone.core.fields.IntField\n",
      "View stages:\n",
      "    1. FilterLabels(field='retinanet_R_50_FPN_3x', filter={'$gt': ['$$this.confidence', 0.15]}, only_matches=True, trajectories=False)\n"
     ]
    }
   ],
   "source": [
    "print(high_conf_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Detection: {\n",
      "    'id': '62a4fc0378ba4622f7c0cd09',\n",
      "    'attributes': BaseDict({}),\n",
      "    'tags': BaseList([]),\n",
      "    'label': 'tv',\n",
      "    'bounding_box': BaseList([\n",
      "        0.005723569169640541,\n",
      "        0.38934000221216625,\n",
      "        0.23573710918426513,\n",
      "        0.2319750360479937,\n",
      "    ]),\n",
      "    'mask': None,\n",
      "    'confidence': 0.8734915256500244,\n",
      "    'index': None,\n",
      "}>\n"
     ]
    }
   ],
   "source": [
    "sample = high_conf_view.first()\n",
    "print(sample.retinanet_R_50_FPN_3x.detections[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view = high_conf_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections...\n",
      " 100% |███████████████| 4990/4990 [6.9m elapsed, 0s remaining, 10.3 samples/s]      \n",
      "Performing IoU sweep...\n",
      " 100% |███████████████| 4990/4990 [3.5m elapsed, 0s remaining, 23.9 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "eval_key=\"retinenet_R_50_fpn_3x\"\n",
    "\n",
    "results = high_conf_view.evaluate_detections(\n",
    "    load_model_name,\n",
    "    gt_field=\"ground_truth\",\n",
    "    eval_key=eval_key,\n",
    "    compute_mAP=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"key\": \"retinenet_R_50_fpn_3x\",\n",
      "    \"version\": \"0.16.2\",\n",
      "    \"timestamp\": \"2022-06-11T20:38:02.135000\",\n",
      "    \"config\": {\n",
      "        \"method\": \"coco\",\n",
      "        \"cls\": \"fiftyone.utils.eval.coco.COCOEvaluationConfig\",\n",
      "        \"pred_field\": \"retinanet_R_50_FPN_3x\",\n",
      "        \"gt_field\": \"ground_truth\",\n",
      "        \"iou\": 0.5,\n",
      "        \"classwise\": true,\n",
      "        \"iscrowd\": \"iscrowd\",\n",
      "        \"use_masks\": false,\n",
      "        \"use_boxes\": false,\n",
      "        \"tolerance\": null,\n",
      "        \"compute_mAP\": true,\n",
      "        \"iou_threshs\": [\n",
      "            0.5,\n",
      "            0.55,\n",
      "            0.6,\n",
      "            0.65,\n",
      "            0.7,\n",
      "            0.75,\n",
      "            0.8,\n",
      "            0.85,\n",
      "            0.9,\n",
      "            0.95\n",
      "        ],\n",
      "        \"max_preds\": 100,\n",
      "        \"error_level\": 1\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(dataset.get_evaluation_info(eval_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "        person       0.48      0.92      0.63     17445\n",
      "           car       0.26      0.85      0.40      2383\n",
      "         chair       0.20      0.71      0.31      2110\n",
      "          book       0.36      0.85      0.51      2832\n",
      "        bottle       0.27      0.82      0.40      1374\n",
      "           cup       0.22      0.78      0.35       952\n",
      "  dining table       0.11      0.66      0.19       719\n",
      " traffic light       0.18      0.69      0.28       656\n",
      "          bowl       0.19      0.78      0.30       653\n",
      "       handbag       0.10      0.57      0.18       540\n",
      "          bird       0.38      0.82      0.52       845\n",
      "          boat       0.24      0.81      0.37       605\n",
      "         truck       0.17      0.84      0.28       419\n",
      "      umbrella       0.30      0.79      0.44       523\n",
      "         bench       0.10      0.56      0.16       437\n",
      "           cow       0.42      0.88      0.57       545\n",
      "        banana       0.34      0.83      0.48       717\n",
      "      backpack       0.11      0.60      0.18       371\n",
      "    motorcycle       0.30      0.84      0.44       460\n",
      "        carrot       0.23      0.81      0.36       611\n",
      "         sheep       0.38      0.89      0.53       515\n",
      "  potted plant       0.14      0.73      0.24       346\n",
      "    wine glass       0.24      0.74      0.36       372\n",
      "         donut       0.42      0.84      0.56       568\n",
      "          kite       0.44      0.85      0.58       544\n",
      "         knife       0.11      0.57      0.18       326\n",
      "       bicycle       0.18      0.72      0.29       325\n",
      "      broccoli       0.19      0.83      0.30       419\n",
      "          cake       0.26      0.81      0.40       417\n",
      "      suitcase       0.28      0.78      0.41       395\n",
      "            tv       0.26      0.82      0.39       288\n",
      "        orange       0.20      0.70      0.31       316\n",
      "           bus       0.34      0.84      0.48       290\n",
      "         pizza       0.23      0.78      0.35       285\n",
      "        remote       0.18      0.68      0.28       283\n",
      "          vase       0.16      0.74      0.27       282\n",
      "         horse       0.25      0.86      0.39       273\n",
      "     surfboard       0.20      0.71      0.31       269\n",
      "         zebra       0.50      0.91      0.65       294\n",
      "         clock       0.29      0.80      0.43       267\n",
      "   sports ball       0.38      0.81      0.52       395\n",
      "    cell phone       0.16      0.68      0.26       262\n",
      "         couch       0.18      0.76      0.29       261\n",
      "      elephant       0.51      0.94      0.66       337\n",
      "           tie       0.20      0.69      0.31       280\n",
      "         spoon       0.10      0.51      0.16       253\n",
      "          skis       0.12      0.68      0.21       241\n",
      "         apple       0.21      0.72      0.33       360\n",
      "       giraffe       0.48      0.89      0.62       232\n",
      "        laptop       0.22      0.77      0.35       231\n",
      "          sink       0.16      0.75      0.26       225\n",
      " tennis racket       0.31      0.81      0.45       225\n",
      "           dog       0.25      0.78      0.38       218\n",
      "          fork       0.15      0.70      0.25       215\n",
      "           cat       0.36      0.91      0.52       202\n",
      "    teddy bear       0.23      0.74      0.35       193\n",
      "         train       0.35      0.84      0.49       190\n",
      "    skateboard       0.25      0.82      0.39       179\n",
      "        toilet       0.34      0.83      0.48       179\n",
      "      sandwich       0.14      0.66      0.24       177\n",
      "           bed       0.16      0.68      0.26       163\n",
      "      keyboard       0.21      0.82      0.34       153\n",
      "baseball glove       0.23      0.66      0.34       148\n",
      "  baseball bat       0.16      0.59      0.26       146\n",
      "      airplane       0.33      0.90      0.49       143\n",
      "          oven       0.16      0.73      0.27       143\n",
      "       hot dog       0.24      0.66      0.36       163\n",
      "  refrigerator       0.18      0.79      0.29       126\n",
      "       frisbee       0.36      0.85      0.50       115\n",
      "         mouse       0.29      0.85      0.43       106\n",
      "  fire hydrant       0.38      0.85      0.53       101\n",
      "     stop sign       0.29      0.79      0.42        75\n",
      "          bear       0.44      0.83      0.58        71\n",
      "     snowboard       0.12      0.64      0.20        69\n",
      " parking meter       0.25      0.63      0.35        60\n",
      "    toothbrush       0.08      0.53      0.14        57\n",
      "     microwave       0.23      0.82      0.36        55\n",
      "      scissors       0.06      0.42      0.11        36\n",
      "    hair drier       0.04      0.27      0.07        11\n",
      "       toaster       0.12      0.78      0.21         9\n",
      "\n",
      "     micro avg       0.29      0.83      0.43     49076\n",
      "     macro avg       0.25      0.75      0.36     49076\n",
      "  weighted avg       0.34      0.83      0.47     49076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the 10 most common classes in the dataset\n",
    "counts = dataset.count_values(\"ground_truth.detections.label\")\n",
    "classes_top = sorted(counts, key=counts.get, reverse=True)\n",
    "\n",
    "# Print a classification report for the top-10 classes\n",
    "results.print_report(classes=classes_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3767741160155552\n"
     ]
    }
   ],
   "source": [
    "print(results.mAP())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59b3c8b4d184c9fa97cb69be64af4ac62d59b4aa4e9f32c8b33c27b6076bd8d0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('objectdetection')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
